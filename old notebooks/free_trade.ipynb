{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Year Country Code  \\\n",
      "0  1983 [YR1983]          USA   \n",
      "1  1984 [YR1984]          USA   \n",
      "2  1985 [YR1985]          USA   \n",
      "3  1986 [YR1986]          USA   \n",
      "4  1987 [YR1987]          USA   \n",
      "\n",
      "   Net trade in goods and services (BoP, current US$)  GDP (current US$)  \\\n",
      "0                                      -5.713500e+10        3.634038e+12   \n",
      "1                                      -1.082770e+11        4.037613e+12   \n",
      "2                                      -1.211020e+11        4.338979e+12   \n",
      "3                                      -1.385270e+11        4.579631e+12   \n",
      "4                                      -1.516750e+11        4.855215e+12   \n",
      "\n",
      "   Consumer price index (2010 = 100)  \\\n",
      "0                          45.676445   \n",
      "1                          47.640776   \n",
      "2                          49.329949   \n",
      "3                          50.266255   \n",
      "4                          52.108294   \n",
      "\n",
      "   Unemployment, total (% of total labor force) (national estimate)  \\\n",
      "0                                                9.6                  \n",
      "1                                                7.5                  \n",
      "2                                                7.2                  \n",
      "3                                                7.0                  \n",
      "4                                                6.2                  \n",
      "\n",
      "   Exports of goods and services (BoP, current US$)  \\\n",
      "0                                      2.660180e+11   \n",
      "1                                      2.910470e+11   \n",
      "2                                      2.890100e+11   \n",
      "3                                      3.100410e+11   \n",
      "4                                      3.488720e+11   \n",
      "\n",
      "   Imports of goods and services (BoP, current US$)  \\\n",
      "0                                      3.231530e+11   \n",
      "1                                      3.993240e+11   \n",
      "2                                      4.101120e+11   \n",
      "3                                      4.485680e+11   \n",
      "4                                      5.005470e+11   \n",
      "\n",
      "   Foreign direct investment, net (BoP, current US$)  \\\n",
      "0                                      -2.730000e+09   \n",
      "1                                      -1.241000e+10   \n",
      "2                                      -5.950000e+09   \n",
      "3                                      -1.142200e+10   \n",
      "4                                      -2.343800e+10   \n",
      "\n",
      "   Official exchange rate (LCU per US$, period average)  \n",
      "0                                                1.0     \n",
      "1                                                1.0     \n",
      "2                                                1.0     \n",
      "3                                                1.0     \n",
      "4                                                1.0     \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import GCNConv, BatchNorm\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'data/MacroKAGCN.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Inspect the data to understand its structure\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/1vzryjd55y9b0xdbmtml14980000gn/T/ipykernel_95376/3479535376.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:277.)\n",
      "  labels = torch.tensor(labels_list, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "# Assuming the dataset has columns for 'Country Code', 'Year', and the various economic indicators\n",
    "features = ['Net trade in goods and services (BoP, current US$)',\n",
    "            'GDP (current US$)',\n",
    "            'Consumer price index (2010 = 100)',\n",
    "            'Unemployment, total (% of total labor force) (national estimate)',\n",
    "            'Exports of goods and services (BoP, current US$)',\n",
    "            'Imports of goods and services (BoP, current US$)',\n",
    "            'Foreign direct investment, net (BoP, current US$)',\n",
    "            'Official exchange rate (LCU per US$, period average)']\n",
    "\n",
    "# Create node features for each country\n",
    "node_features_list = []\n",
    "labels_list = []\n",
    "country_codes = data['Country Code'].unique()\n",
    "\n",
    "for country in country_codes:\n",
    "    country_data = data[data['Country Code'] == country]\n",
    "    \n",
    "    # Create node features\n",
    "    node_features_list.append(country_data[features].values)\n",
    "    \n",
    "    # Create labels (next year's exchange rate)\n",
    "    next_year_exchange_rate = country_data['Official exchange rate (LCU per US$, period average)'].shift(-1)\n",
    "    \n",
    "    # Drop the last row to ensure matching lengths\n",
    "    country_data = country_data.iloc[:-1]\n",
    "    \n",
    "    # Append the features and labels\n",
    "    node_features_list[-1] = country_data[features].values\n",
    "    labels_list.append(next_year_exchange_rate.iloc[:-1].values)\n",
    "\n",
    "\n",
    "# Convert to tensors\n",
    "node_features = torch.tensor(np.concatenate(node_features_list), dtype=torch.float)\n",
    "labels = torch.tensor(labels_list, dtype=torch.float)\n",
    "\n",
    "# Normalize node features\n",
    "scaler = StandardScaler()\n",
    "node_features = torch.tensor(scaler.fit_transform(node_features), dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 40])\n"
     ]
    }
   ],
   "source": [
    "# Create edge index and set all edge weights to 1\n",
    "edge_index = []\n",
    "edge_attr = []\n",
    "\n",
    "# Create a fully connected graph with all edges having weight 1\n",
    "for i in range(len(country_codes)):\n",
    "    for j in range(i + 1, len(country_codes)):\n",
    "        edge_index.append([i, j])\n",
    "        edge_index.append([j, i])  # Assuming undirected graph\n",
    "        edge_attr.append(1.0)\n",
    "        edge_attr.append(1.0)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "# Create PyTorch Geometric data object\n",
    "from torch_geometric.data import Data\n",
    "graph_data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr, y=labels)\n",
    "\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create edge index and set all edge weights to 1\n",
    "edge_index = []\n",
    "edge_attr = []\n",
    "\n",
    "# Create a fully connected graph with all edges having weight 1\n",
    "for i in range(len(country_codes)):\n",
    "    for j in range(i + 1, len(country_codes)):\n",
    "        edge_index.append([i, j])\n",
    "        edge_index.append([j, i])  # Assuming undirected graph\n",
    "        edge_attr.append(1.0)\n",
    "        edge_attr.append(1.0)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAGCN(\n",
      "  (conv1): GCNConv(8, 128)\n",
      "  (bn1): BatchNorm(128)\n",
      "  (conv2): GCNConv(128, 128)\n",
      "  (bn2): BatchNorm(128)\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv, BatchNorm, GATConv\n",
    "\n",
    "class KAGCN(nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_dim, output_dim=6, dropout=0.3):\n",
    "        super(KAGCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_dim)\n",
    "        self.bn1 = BatchNorm(hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.bn2 = BatchNorm(hidden_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)  # Output layer for 6 countries\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)  # Final output is a vector with 6 elements\n",
    "\n",
    "        # Reshape if needed to ensure correct output shape, depending on how your data is structured\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify input dimensions before running the model\n",
    "model = KAGCN(num_node_features=node_features.shape[1], hidden_dim=128, output_dim=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gradients(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and param.grad is not None:\n",
    "            print(f\"{name} grad mean: {param.grad.mean()}\")\n",
    "\n",
    "\n",
    "# Apply gradient clipping during training\n",
    "def train_model(model, data, labels, num_epochs=500, learning_rate=0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.SmoothL1Loss()  # Using Huber Loss here\n",
    "    max_norm = 1.0  # Set max norm for gradient clipping\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(data.x, data.edge_index, data.edge_attr)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # After loss.backward() and before optimizer.step()\n",
    "        #check_gradients(model)\n",
    "        # Clip gradients to avoid explosion\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (240) must match the size of tensor b (6) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[230], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Ensure the model is in evaluation mode\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[0;32mIn[226], line 18\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, data, labels, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39medge_attr)\n\u001b[0;32m---> 18\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# After loss.backward() and before optimizer.step()\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#check_gradients(model)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Clip gradients to avoid explosion\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/loss.py:939\u001b[0m, in \u001b[0;36mSmoothL1Loss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 939\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmooth_l1_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/functional.py:3265\u001b[0m, in \u001b[0;36msmooth_l1_loss\u001b[0;34m(input, target, size_average, reduce, reduction, beta)\u001b[0m\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3263\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3265\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m   3268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39ml1_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/functional.py:76\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (240) must match the size of tensor b (6) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, graph_data, num_epochs=500, learning_rate=0.001, labels=)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(graph_data.x, graph_data.edge_index, graph_data.edge_attr)\n",
    "\n",
    "# Reshape predictions to match the expected shape\n",
    "predictions = predictions.view(-1, 6).numpy()\n",
    "labels_np = labels.view(-1, 6).numpy()\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse = mean_squared_error(labels_np, predictions)\n",
    "print(f\"Test MSE: {mse}\")\n",
    "\n",
    "# Visualize the predictions vs. actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, country in enumerate(country_codes):\n",
    "    plt.plot(labels_np[:, i], label=f'Actual {country}')\n",
    "    plt.plot(predictions[:, i], label=f'Predicted {country}', linestyle='dashed')\n",
    "    print(f'Predicted {country}', predictions[i])\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Exchange Rate\")\n",
    "plt.title(\"Actual vs Predicted Exchange Rates\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can only convert an array of size 1 to a Python scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[223], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example prediction for the next year\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, country \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(country_codes):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCountry: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Predicted Exchange Rate for Next Year: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar"
     ]
    }
   ],
   "source": [
    "# Example prediction for the next year\n",
    "for i, country in enumerate(country_codes):\n",
    "    print(f\"Country: {country}, Predicted Exchange Rate for Next Year: {predictions[i].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
