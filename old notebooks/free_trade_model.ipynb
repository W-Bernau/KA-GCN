{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare the Mock Dataset (same as before)\n",
    "years = 41\n",
    "start_year = 1983\n",
    "end_year = 2023\n",
    "\n",
    "data = {\n",
    "    'Year': list(range(start_year, end_year + 1)) * 15,\n",
    "    'Country_A': ['USA', 'USA', 'USA', 'USA', 'USA', 'UK', 'UK', 'UK', 'UK', 'Canada', 'Canada', 'Canada', 'Italy', 'Italy', 'France'] * years,\n",
    "    'Country_B': ['UK', 'Canada', 'Italy', 'France', 'Germany', 'Canada', 'Italy', 'France', 'Germany', 'Italy', 'France', 'Germany', 'France', 'Germany', 'Germany'] * years,\n",
    "                  \n",
    "    'Free_Trade': [1 for _ in range(15 * years)]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "countries = list(set(df['Country_A'].tolist() + df['Country_B'].tolist()))\n",
    "country_to_index = {country: i for i, country in enumerate(countries)}\n",
    "\n",
    "edge_index = torch.tensor([[country_to_index[row['Country_A']], country_to_index[row['Country_B']]] for _, row in df.iterrows()], dtype=torch.long).t().contiguous()\n",
    "\n",
    "edge_attr = torch.tensor(df['Free_Trade'].values, dtype=torch.float)\n",
    "\n",
    "features = {\n",
    "    'USA': [1.00, 21000, 2.0],\n",
    "    'UK': [6.50, 14000, 3.0],\n",
    "    'Germany': [0.85, 3800, 1.5],\n",
    "    'Canada': [1.25, 1700, 2.5],\n",
    "    'Italy': [110.00, 5000, 1.0],\n",
    "    'France': [110.00, 5000, 1.0]\n",
    "    \n",
    "}\n",
    "\n",
    "node_features = torch.tensor([features[country] for country in countries], dtype=torch.float)\n",
    "\n",
    "exchange_rates = {\n",
    "    'USA': 1.00,\n",
    "    'UK': 6.50,\n",
    "    'Germany': 0.85,\n",
    "    'Canada': 1.25,\n",
    "    'Italy': 110.00,\n",
    "    'France': 110.00\n",
    "}\n",
    "\n",
    "previous_exchange_rates = {\n",
    "    'USA': 1.00,\n",
    "    'UK': 6.48,\n",
    "    'Germany': 0.87,\n",
    "    'Canada': 1.23,\n",
    "    'Italy': 111.00,\n",
    "    'France': 110.00\n",
    "}\n",
    "\n",
    "labels = torch.tensor([exchange_rates[country] - previous_exchange_rates[country] for country in countries], dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the Enhanced KA-GCN Model\n",
    "\n",
    "class SuperKAGCN(nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_dim, output_dim, dropout=0.3):\n",
    "        super(SuperKAGCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_dim)\n",
    "        self.bn1 = BatchNorm(hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.bn2 = BatchNorm(hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.bn3 = BatchNorm(hidden_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Implement Training with Advanced Techniques\n",
    "\n",
    "def train_model(model, data, labels, num_epochs=500, patience=20):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=10, min_lr=1e-6, verbose=True)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(data.x, data.edge_index, data.edge_attr)\n",
    "        loss = criterion(out.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step(loss)\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_model = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(best_model)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Normalization and Data Preparation\n",
    "\n",
    "# Normalize node features (standard normalization)\n",
    "node_features = (node_features - node_features.mean(dim=0)) / node_features.std(dim=0)\n",
    "\n",
    "# Normalize edge attributes (min-max normalization)\n",
    "edge_attr = (edge_attr - edge_attr.min()) / (edge_attr.max() - edge_attr.min())\n",
    "\n",
    "# Prepare the data object\n",
    "data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr, y=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan\n",
      "Epoch 10, Loss: nan\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected state_dict to be dict-like, got <class 'NoneType'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 5: Train the Model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m SuperKAGCN(num_node_features\u001b[38;5;241m=\u001b[39mnode_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 37\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, data, labels, num_epochs, patience)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEarly stopping at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:2140\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.\u001b[39;00m\n\u001b[1;32m   2106\u001b[0m \n\u001b[1;32m   2107\u001b[0m \u001b[38;5;124;03mIf :attr:`strict` is ``True``, then\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2137\u001b[0m \u001b[38;5;124;03m    ``RuntimeError``.\u001b[39;00m\n\u001b[1;32m   2138\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(state_dict, Mapping):\n\u001b[0;32m-> 2140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected state_dict to be dict-like, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(state_dict)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2142\u001b[0m missing_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2143\u001b[0m unexpected_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected state_dict to be dict-like, got <class 'NoneType'>."
     ]
    }
   ],
   "source": [
    "# Step 5: Train the Model\n",
    "\n",
    "model = SuperKAGCN(num_node_features=node_features.shape[1], hidden_dim=64, output_dim=1, dropout=0.3)\n",
    "model = train_model(model, data, labels, num_epochs=500, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: USA, Predicted Change in Exchange Rate: Decrease, Value: -0.0176653154194355\n",
      "Country: Italy, Predicted Change in Exchange Rate: Increase, Value: 0.0027642855420708656\n",
      "Country: UK, Predicted Change in Exchange Rate: Increase, Value: 0.022893346846103668\n",
      "Country: Germany, Predicted Change in Exchange Rate: Decrease, Value: -0.011166456155478954\n",
      "Country: Canada, Predicted Change in Exchange Rate: Increase, Value: 0.0040656146593391895\n",
      "Country: France, Predicted Change in Exchange Rate: Decrease, Value: -0.004892876371741295\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Make Predictions\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(data.x, data.edge_index, data.edge_attr)\n",
    "\n",
    "# Interpret the predictions\n",
    "for i, pred in enumerate(predictions):\n",
    "    country = countries[i]\n",
    "    change = 'Increase' if pred.item() > 0 else 'Decrease'\n",
    "    print(f'Country: {country}, Predicted Change in Exchange Rate: {change}, Value: {pred.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
